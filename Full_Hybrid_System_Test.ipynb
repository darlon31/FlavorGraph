{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darlon31/FlavorGraph/blob/master/Full_Hybrid_System_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWgrgzpp_7Y3"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Setup and Dependencies\n",
        "!pip install -q transformers torch networkx pandas numpy scikit-learn matplotlib seaborn tqdm gdown\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fc8SAm1Ji3v",
        "outputId": "095dcb13-3ca4-4d43-a62a-e304be1b603d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# CELL 2: Mount Google Drive and Setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Make sure we're in the content directory and clean up\n",
        "os.chdir('/content')\n",
        "!rm -rf /content/FlavorGraph\n",
        "logger.info(\"Environment prepared\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Clone Repository and Check Structure\n",
        "# Clone the repository\n",
        "!git clone https://github.com/darlon31/FlavorGraph.git\n",
        "logger.info(\"FlavorGraph repository cloned successfully\")\n",
        "\n",
        "# Check the actual structure\n",
        "print(\"\\nChecking actual directory structure:\")\n",
        "!ls -R /content/FlavorGraph\n",
        "\n",
        "# Change to the FlavorGraph directory\n",
        "os.chdir('FlavorGraph')\n",
        "logger.info(f\"Current working directory: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TYzuyp9OK7QT",
        "outputId": "5c6e6c15-56ea-4126-94ce-101a3e05ac0c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FlavorGraph'...\n",
            "remote: Enumerating objects: 327, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 327 (delta 42), reused 58 (delta 33), pack-reused 249 (from 1)\u001b[K\n",
            "Receiving objects: 100% (327/327), 20.83 MiB | 18.96 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n",
            "\n",
            "Checking actual directory structure:\n",
            "/content/FlavorGraph:\n",
            "images\tinput  LICENSE\toutput\tREADME.md  src\n",
            "\n",
            "/content/FlavorGraph/images:\n",
            "embeddings.png\tflavorgraph2vec.png  flavorgraph.png\n",
            "\n",
            "/content/FlavorGraph/input:\n",
            "'dict_ingr2cate - Top300+FDB400+HyperFoods104=616.csv'\t node_classification_hub.csv\n",
            " edges_191120.csv\t\t\t\t\t nodes_191120.csv\n",
            "\n",
            "/content/FlavorGraph/output:\n",
            " kitchenette_embeddings.pkl  'place output files here'\n",
            "\n",
            "/content/FlavorGraph/src:\n",
            "dataloader.py  graph2vec.py  main.py  model.py\tparser.py  plotter.py  utils.py  walkers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Configuration and Path Verification\n",
        "class Config:\n",
        "    \"\"\"Configuration class for the FlavorGraph Hybrid Recipe System\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Detect environment\n",
        "        self.IN_COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "        # Base paths\n",
        "        if self.IN_COLAB:\n",
        "            self.BASE_DIR = \"/content/FlavorGraph\"\n",
        "        else:\n",
        "            self.BASE_DIR = \"c:/Users/dario/FlavorGraph\"\n",
        "\n",
        "        # Directory structure - using the correct paths as shown in the repository\n",
        "        self.INPUT_DIR = os.path.join(self.BASE_DIR, \"input\")\n",
        "        self.OUTPUT_DIR = os.path.join(self.BASE_DIR, \"output\")\n",
        "        self.SRC_DIR = os.path.join(self.BASE_DIR, \"src\")\n",
        "\n",
        "        # Data files with exact names from the repository\n",
        "        self.NODES_FILE = os.path.join(self.INPUT_DIR, \"nodes_191120.csv\")\n",
        "        self.EDGES_FILE = os.path.join(self.INPUT_DIR, \"edges_191120.csv\")\n",
        "        self.CATEGORIES_FILE = os.path.join(self.INPUT_DIR, \"dict_ingr2cate - Top300+FDB400+HyperFoods104=616.csv\")\n",
        "        self.NODE_CLASSIFICATION_FILE = os.path.join(self.INPUT_DIR, \"node_classification_hub.csv\")\n",
        "        self.EMBEDDING_FILE = os.path.join(self.OUTPUT_DIR, \"kitchenette_embeddings.pkl\")\n",
        "\n",
        "        # Model settings\n",
        "        self.EMBEDDING_DIM = 300\n",
        "        self.MOLECULAR_DIM = 881\n",
        "        self.MODEL_NAME = \"flax-community/t5-recipe-generation\"\n",
        "        self.MODEL_CACHE_DIR = os.path.join(self.BASE_DIR, \"model_cache\")\n",
        "\n",
        "        # Generation settings\n",
        "        self.GENERATION_CONFIG = {\n",
        "            \"max_length\": 512,\n",
        "            \"min_length\": 64,\n",
        "            \"no_repeat_ngram_size\": 3,\n",
        "            \"do_sample\": True,\n",
        "            \"top_k\": 60,\n",
        "            \"top_p\": 0.95,\n",
        "            \"temperature\": 0.7\n",
        "        }\n",
        "\n",
        "        # Hybrid settings\n",
        "        self.SIMILARITY_THRESHOLD = 0.7\n",
        "        self.MAX_SIMILAR_INGREDIENTS = 3\n",
        "\n",
        "    def verify_paths(self):\n",
        "        \"\"\"Verify all paths exist and log their status\"\"\"\n",
        "        paths = {\n",
        "            'BASE_DIR': self.BASE_DIR,\n",
        "            'INPUT_DIR': self.INPUT_DIR,\n",
        "            'OUTPUT_DIR': self.OUTPUT_DIR,\n",
        "            'SRC_DIR': self.SRC_DIR,\n",
        "            'NODES_FILE': self.NODES_FILE,\n",
        "            'EDGES_FILE': self.EDGES_FILE,\n",
        "            'CATEGORIES_FILE': self.CATEGORIES_FILE,\n",
        "            'NODE_CLASSIFICATION_FILE': self.NODE_CLASSIFICATION_FILE,\n",
        "            'EMBEDDING_FILE': self.EMBEDDING_FILE\n",
        "        }\n",
        "\n",
        "        all_exist = True\n",
        "        logger.info(\"\\nVerifying paths:\")\n",
        "        for name, path in paths.items():\n",
        "            if os.path.exists(path):\n",
        "                if os.path.isfile(path):\n",
        "                    size = os.path.getsize(path)\n",
        "                    logger.info(f\"{name}: ✓ ({path}) - Size: {size/1024:.2f} KB\")\n",
        "                else:\n",
        "                    logger.info(f\"{name}: ✓ ({path}) - Directory\")\n",
        "            else:\n",
        "                logger.warning(f\"{name}: ✗ ({path}) - Not found\")\n",
        "                all_exist = False\n",
        "        return all_exist\n",
        "\n",
        "# Create and verify configuration\n",
        "config = Config()\n",
        "logger.info(f\"Running in Colab: {config.IN_COLAB}\")\n",
        "logger.info(f\"Current working directory: {os.getcwd()}\")\n",
        "logger.info(f\"Base directory: {config.BASE_DIR}\")\n",
        "\n",
        "if not config.verify_paths():\n",
        "    logger.warning(\"Some required paths are missing!\")\n",
        "else:\n",
        "    logger.info(\"All paths verified successfully!\")\n",
        "\n",
        "# Print out all available files in input and output directories for verification\n",
        "print(\"\\nInput directory contents:\")\n",
        "!ls -l {config.INPUT_DIR}\n",
        "print(\"\\nOutput directory contents:\")\n",
        "!ls -l {config.OUTPUT_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-AcbP7YLavq",
        "outputId": "defa8ccd-1091-47a9-f7a5-a32b9d5bcc15"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input directory contents:\n",
            "total 5392\n",
            "-rw-r--r-- 1 root root   16219 Nov 30 13:05 'dict_ingr2cate - Top300+FDB400+HyperFoods104=616.csv'\n",
            "-rw-r--r-- 1 root root 5155973 Nov 30 13:05  edges_191120.csv\n",
            "-rw-r--r-- 1 root root    1484 Nov 30 13:05  node_classification_hub.csv\n",
            "-rw-r--r-- 1 root root  343416 Nov 30 13:05  nodes_191120.csv\n",
            "\n",
            "Output directory contents:\n",
            "total 8644\n",
            "-rw-r--r-- 1 root root 8845756 Nov 30 13:05  kitchenette_embeddings.pkl\n",
            "-rw-r--r-- 1 root root      25 Nov 30 13:05 'place output files here'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Setup Hybrid System Structure\n",
        "# Create hybrid_system directory\n",
        "!mkdir -p /content/FlavorGraph/hybrid_system\n",
        "\n",
        "# Create necessary Python files\n",
        "hybrid_files = {\n",
        "    'config.py': '''import os\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class for the FlavorGraph Hybrid Recipe System\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Detect environment\n",
        "        self.IN_COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "        # Base paths\n",
        "        if self.IN_COLAB:\n",
        "            self.BASE_DIR = \"/content/FlavorGraph\"\n",
        "        else:\n",
        "            self.BASE_DIR = \"c:/Users/dario/FlavorGraph\"\n",
        "\n",
        "        # Directory structure\n",
        "        self.INPUT_DIR = os.path.join(self.BASE_DIR, \"input\")\n",
        "        self.OUTPUT_DIR = os.path.join(self.BASE_DIR, \"output\")\n",
        "        self.SRC_DIR = os.path.join(self.BASE_DIR, \"src\")\n",
        "\n",
        "        # Data files\n",
        "        self.NODES_FILE = os.path.join(self.INPUT_DIR, \"nodes_191120.csv\")\n",
        "        self.EDGES_FILE = os.path.join(self.INPUT_DIR, \"edges_191120.csv\")\n",
        "        self.CATEGORIES_FILE = os.path.join(self.INPUT_DIR, \"dict_ingr2cate - Top300+FDB400+HyperFoods104=616.csv\")\n",
        "        self.NODE_CLASSIFICATION_FILE = os.path.join(self.INPUT_DIR, \"node_classification_hub.csv\")\n",
        "        self.EMBEDDING_FILE = os.path.join(self.OUTPUT_DIR, \"kitchenette_embeddings.pkl\")\n",
        "\n",
        "        # Model settings\n",
        "        self.EMBEDDING_DIM = 300\n",
        "        self.MOLECULAR_DIM = 881\n",
        "        self.MODEL_NAME = \"flax-community/t5-recipe-generation\"\n",
        "        self.MODEL_CACHE_DIR = os.path.join(self.BASE_DIR, \"model_cache\")\n",
        "\n",
        "        # Generation settings\n",
        "        self.GENERATION_CONFIG = {\n",
        "            \"max_length\": 512,\n",
        "            \"min_length\": 64,\n",
        "            \"no_repeat_ngram_size\": 3,\n",
        "            \"do_sample\": True,\n",
        "            \"top_k\": 60,\n",
        "            \"top_p\": 0.95,\n",
        "            \"temperature\": 0.7\n",
        "        }\n",
        "\n",
        "        # Hybrid settings\n",
        "        self.SIMILARITY_THRESHOLD = 0.7\n",
        "        self.MAX_SIMILAR_INGREDIENTS = 3\n",
        "\n",
        "    def verify_paths(self):\n",
        "        \"\"\"Verify all paths exist and log their status\"\"\"\n",
        "        paths = {\n",
        "            'BASE_DIR': self.BASE_DIR,\n",
        "            'INPUT_DIR': self.INPUT_DIR,\n",
        "            'OUTPUT_DIR': self.OUTPUT_DIR,\n",
        "            'SRC_DIR': self.SRC_DIR,\n",
        "            'NODES_FILE': self.NODES_FILE,\n",
        "            'EDGES_FILE': self.EDGES_FILE,\n",
        "            'CATEGORIES_FILE': self.CATEGORIES_FILE,\n",
        "            'NODE_CLASSIFICATION_FILE': self.NODE_CLASSIFICATION_FILE,\n",
        "            'EMBEDDING_FILE': self.EMBEDDING_FILE\n",
        "        }\n",
        "\n",
        "        all_exist = True\n",
        "        logger.info(\"\\\\nVerifying paths:\")\n",
        "        for name, path in paths.items():\n",
        "            if os.path.exists(path):\n",
        "                if os.path.isfile(path):\n",
        "                    size = os.path.getsize(path)\n",
        "                    logger.info(f\"{name}: ✓ ({path}) - Size: {size/1024:.2f} KB\")\n",
        "                else:\n",
        "                    logger.info(f\"{name}: ✓ ({path}) - Directory\")\n",
        "            else:\n",
        "                logger.warning(f\"{name}: ✗ ({path}) - Not found\")\n",
        "                all_exist = False\n",
        "        return all_exist''',\n",
        "    'ingredient_processor.py': '''from config import Config\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "\n",
        "class IngredientProcessor:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Load all necessary data files\"\"\"\n",
        "        # Load ingredient nodes\n",
        "        self.nodes_df = pd.read_csv(self.config.NODES_FILE)\n",
        "\n",
        "        # Load categories\n",
        "        self.categories_df = pd.read_csv(self.config.CATEGORIES_FILE)\n",
        "\n",
        "        # Load embeddings\n",
        "        with open(self.config.EMBEDDING_FILE, 'rb') as f:\n",
        "            self.embeddings = pickle.load(f)\n",
        "''',\n",
        "    'recipe_generator.py': '''from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "from config import Config\n",
        "import torch\n",
        "\n",
        "class RecipeGenerator:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the T5 model and tokenizer\"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.config.MODEL_NAME)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(self.config.MODEL_NAME)\n",
        "        self.model.to(self.device)\n",
        "''',\n",
        "    'test_config.py': '''import unittest\n",
        "from config import Config\n",
        "import os\n",
        "\n",
        "class TestConfig(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.config = Config()\n",
        "\n",
        "    def test_paths_exist(self):\n",
        "        \"\"\"Test that all required paths exist\"\"\"\n",
        "        self.assertTrue(self.config.verify_paths())\n",
        "''',\n",
        "    'test_hybrid.py': '''import unittest\n",
        "from config import Config\n",
        "from ingredient_processor import IngredientProcessor\n",
        "from recipe_generator import RecipeGenerator\n",
        "\n",
        "class TestHybridSystem(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.config = Config()\n",
        "        self.ingredient_processor = IngredientProcessor(self.config)\n",
        "        self.recipe_generator = RecipeGenerator(self.config)\n",
        "'''\n",
        "}\n",
        "\n",
        "# Write files to hybrid_system directory\n",
        "for filename, content in hybrid_files.items():\n",
        "    filepath = f'/content/FlavorGraph/hybrid_system/{filename}'\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "print(\"Created hybrid system files:\")\n",
        "!ls -l /content/FlavorGraph/hybrid_system/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Yr6W8ALs-1",
        "outputId": "38b6bc68-0685-4685-e90d-1f7232953f3f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created hybrid system files:\n",
            "total 20\n",
            "-rw-r--r-- 1 root root 3024 Nov 30 13:08 config.py\n",
            "-rw-r--r-- 1 root root  663 Nov 30 13:08 ingredient_processor.py\n",
            "-rw-r--r-- 1 root root  585 Nov 30 13:08 recipe_generator.py\n",
            "-rw-r--r-- 1 root root  284 Nov 30 13:08 test_config.py\n",
            "-rw-r--r-- 1 root root  366 Nov 30 13:08 test_hybrid.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Setup System Components\n",
        "import os\n",
        "\n",
        "# Create hybrid_system directory\n",
        "os.makedirs('/content/FlavorGraph/hybrid_system', exist_ok=True)\n",
        "\n",
        "# Update recipe_generator.py\n",
        "recipe_generator_code = '''from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class RecipeGenerator:\n",
        "    def __init__(self, config):\n",
        "        \"\"\"Initialize the recipe generation model\"\"\"\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        logger.info(f\"Loading recipe generation model on {self.device}...\")\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.config.MODEL_NAME,\n",
        "            cache_dir=self.config.MODEL_CACHE_DIR\n",
        "        )\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(\n",
        "            self.config.MODEL_NAME,\n",
        "            cache_dir=self.config.MODEL_CACHE_DIR\n",
        "        ).to(self.device)\n",
        "\n",
        "        logger.info(\"Recipe generation model loaded successfully!\")\n",
        "\n",
        "    def generate_recipe(self, ingredients):\n",
        "        \"\"\"Generate a recipe from a list of ingredients\"\"\"\n",
        "        # Format input\n",
        "        input_text = f\"ingredients: {', '.join(ingredients)}\"\n",
        "        input_ids = self.tokenizer(\n",
        "            input_text,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512,\n",
        "            truncation=True\n",
        "        ).input_ids.to(self.device)\n",
        "\n",
        "        # Generate recipe\n",
        "        outputs = self.model.generate(\n",
        "            input_ids,\n",
        "            **self.config.GENERATION_CONFIG\n",
        "        )\n",
        "\n",
        "        # Decode and return\n",
        "        recipe = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return recipe'''\n",
        "\n",
        "# Write recipe_generator.py\n",
        "with open('/content/FlavorGraph/hybrid_system/recipe_generator.py', 'w') as f:\n",
        "    f.write(recipe_generator_code)\n",
        "\n",
        "# Update ingredient_processor.py\n",
        "ingredient_processor_code = '''from config import Config\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class IngredientProcessor:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self._load_data()\n",
        "\n",
        "    def _normalize_ingredient_name(self, name):\n",
        "        \"\"\"Normalize ingredient name for consistent matching\"\"\"\n",
        "        # Convert to lowercase and remove spaces\n",
        "        norm_name = name.lower().strip()\n",
        "\n",
        "        # Handle plural forms\n",
        "        if norm_name.endswith('es'):\n",
        "            norm_name = norm_name[:-2]\n",
        "        elif norm_name.endswith('s'):\n",
        "            norm_name = norm_name[:-1]\n",
        "\n",
        "        # Replace spaces with underscores\n",
        "        norm_name = norm_name.replace(' ', '_')\n",
        "\n",
        "        # Common substitutions\n",
        "        substitutions = {\n",
        "            'tomatoes': 'tomato',\n",
        "            'onions': 'onion',\n",
        "            'garlic_cloves': 'garlic',\n",
        "            'garlic_clove': 'garlic',\n",
        "            'bell_peppers': 'bell_pepper',\n",
        "            'carrots': 'carrot'\n",
        "        }\n",
        "\n",
        "        return substitutions.get(norm_name, norm_name)\n",
        "\n",
        "    def _load_data(self):\n",
        "        \"\"\"Load all necessary data files\"\"\"\n",
        "        logger.info(\"Loading ingredient data...\")\n",
        "        # Load ingredient nodes and clean data\n",
        "        self.nodes_df = pd.read_csv(self.config.NODES_FILE)\n",
        "        self.nodes_df = self.nodes_df.dropna(subset=['name'])\n",
        "        self.nodes_df['name'] = self.nodes_df['name'].astype(str)\n",
        "\n",
        "        # Load categories\n",
        "        self.categories_df = pd.read_csv(self.config.CATEGORIES_FILE)\n",
        "\n",
        "        # Load embeddings and create mapping\n",
        "        with open(self.config.EMBEDDING_FILE, 'rb') as f:\n",
        "            embeddings_dict = pickle.load(f)\n",
        "\n",
        "        # Create name to embedding mapping\n",
        "        self.name_to_embedding = {}\n",
        "        self.embeddings_list = []\n",
        "        self.valid_ingredients = []\n",
        "\n",
        "        for name in self.nodes_df['name']:\n",
        "            try:\n",
        "                # Try both original and normalized names\n",
        "                norm_name = self._normalize_ingredient_name(name)\n",
        "                if norm_name in embeddings_dict:\n",
        "                    self.name_to_embedding[name] = len(self.embeddings_list)\n",
        "                    self.embeddings_list.append(embeddings_dict[norm_name])\n",
        "                    self.valid_ingredients.append(name)\n",
        "            except AttributeError:\n",
        "                continue\n",
        "\n",
        "        if not self.embeddings_list:\n",
        "            raise ValueError(\"No valid embeddings found!\")\n",
        "\n",
        "        self.embeddings = np.array(self.embeddings_list)\n",
        "        logger.info(f\"Successfully loaded {len(self.valid_ingredients)} ingredients with embeddings\")\n",
        "\n",
        "    def find_similar_ingredients(self, ingredient_name, n=3):\n",
        "        \"\"\"Find similar ingredients based on embedding similarity\"\"\"\n",
        "        # Normalize input name\n",
        "        norm_name = self._normalize_ingredient_name(ingredient_name)\n",
        "\n",
        "        # Try both original and normalized names\n",
        "        if ingredient_name in self.name_to_embedding:\n",
        "            idx = self.name_to_embedding[ingredient_name]\n",
        "        elif norm_name in self.name_to_embedding:\n",
        "            idx = self.name_to_embedding[norm_name]\n",
        "        else:\n",
        "            raise ValueError(f\"No embedding found for ingredient '{ingredient_name}' (normalized: '{norm_name}')\")\n",
        "\n",
        "        ingredient_embedding = self.embeddings[idx].reshape(1, -1)\n",
        "        similarities = cosine_similarity(ingredient_embedding, self.embeddings)[0]\n",
        "\n",
        "        # Get top similar ingredients (excluding self)\n",
        "        similar_indices = np.argsort(similarities)[::-1][1:n*2]  # Get more candidates for filtering\n",
        "\n",
        "        # Get category of original ingredient\n",
        "        original_category = self.get_ingredient_category(self.valid_ingredients[idx])\n",
        "\n",
        "        # Filter and sort candidates\n",
        "        similar_ingredients = []\n",
        "        for idx in similar_indices:\n",
        "            ingredient = self.valid_ingredients[idx]\n",
        "            category = self.get_ingredient_category(ingredient)\n",
        "\n",
        "            # Skip ingredients that are too similar in name\n",
        "            if ingredient.lower() in ingredient_name.lower() or ingredient_name.lower() in ingredient.lower():\n",
        "                continue\n",
        "\n",
        "            similar_ingredients.append({\n",
        "                'name': ingredient,\n",
        "                'similarity': similarities[idx],\n",
        "                'category': category\n",
        "            })\n",
        "\n",
        "            if len(similar_ingredients) >= n:\n",
        "                break\n",
        "\n",
        "        return similar_ingredients\n",
        "\n",
        "    def get_ingredient_category(self, ingredient_name):\n",
        "        \"\"\"Get category for an ingredient\"\"\"\n",
        "        # Try exact match first\n",
        "        category_row = self.categories_df[self.categories_df['ingredient'] == ingredient_name]\n",
        "        if len(category_row) > 0:\n",
        "            return category_row['category'].iloc[0]\n",
        "\n",
        "        # Try normalized match\n",
        "        norm_name = self._normalize_ingredient_name(ingredient_name)\n",
        "        category_row = self.categories_df[self.categories_df['ingredient'].str.lower().str.replace(' ', '_') == norm_name]\n",
        "        return category_row['category'].iloc[0] if len(category_row) > 0 else 'Unknown'\n",
        "\n",
        "    def suggest_substitutions(self, ingredient_name, n=3, same_category_only=True):\n",
        "        \"\"\"Suggest ingredient substitutions with preference for same category\"\"\"\n",
        "        if ingredient_name not in self.name_to_embedding:\n",
        "            norm_name = self._normalize_ingredient_name(ingredient_name)\n",
        "            if norm_name not in self.name_to_embedding:\n",
        "                raise ValueError(f\"No embedding found for ingredient '{ingredient_name}' (normalized: '{norm_name}')\")\n",
        "\n",
        "        # Get original ingredient's category\n",
        "        original_category = self.get_ingredient_category(ingredient_name)\n",
        "\n",
        "        # Get similar ingredients\n",
        "        similar_ingredients = self.find_similar_ingredients(ingredient_name, n=n*2 if same_category_only else n)\n",
        "\n",
        "        if same_category_only:\n",
        "            # Filter for same category and take top n\n",
        "            same_category_substitutes = [\n",
        "                ing for ing in similar_ingredients\n",
        "                if ing['category'] == original_category\n",
        "            ][:n]\n",
        "\n",
        "            # If we don't have enough same-category substitutes, add others\n",
        "            if len(same_category_substitutes) < n:\n",
        "                other_substitutes = [\n",
        "                    ing for ing in similar_ingredients\n",
        "                    if ing['category'] != original_category\n",
        "                ][:n - len(same_category_substitutes)]\n",
        "                same_category_substitutes.extend(other_substitutes)\n",
        "\n",
        "            return same_category_substitutes\n",
        "\n",
        "        return similar_ingredients\n",
        "\n",
        "    def generate_recipe_variations(self, ingredients, n_variations=3):\n",
        "        \"\"\"Generate recipe variations by substituting ingredients\"\"\"\n",
        "        variations = []\n",
        "        for _ in range(n_variations):\n",
        "            variation = []\n",
        "            for ingredient in ingredients:\n",
        "                try:\n",
        "                    # 30% chance to substitute each ingredient\n",
        "                    if np.random.random() < 0.3:\n",
        "                        substitutes = self.suggest_substitutions(ingredient, n=1)\n",
        "                        if substitutes:\n",
        "                            variation.append(substitutes[0]['name'])\n",
        "                        else:\n",
        "                            variation.append(ingredient)\n",
        "                    else:\n",
        "                        variation.append(ingredient)\n",
        "                except ValueError:\n",
        "                    variation.append(ingredient)\n",
        "            variations.append(variation)\n",
        "        return variations\n",
        "\n",
        "    def print_data_stats(self):\n",
        "        \"\"\"Print statistics about the loaded data\"\"\"\n",
        "        print(\"\\\\nData Statistics:\")\n",
        "        print(f\"Total nodes in dataset: {len(self.nodes_df)}\")\n",
        "        print(f\"Valid ingredients with embeddings: {len(self.valid_ingredients)}\")\n",
        "        print(f\"Total categories: {len(self.categories_df['category'].unique())}\")\n",
        "        print(\"\\\\nSample of valid ingredients:\")\n",
        "        print(np.random.choice(self.valid_ingredients, 5))'''\n",
        "\n",
        "# Write ingredient_processor.py\n",
        "with open('/content/FlavorGraph/hybrid_system/ingredient_processor.py', 'w') as f:\n",
        "    f.write(ingredient_processor_code)\n",
        "\n",
        "print(\"Files updated successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV_8EHZGSSEw",
        "outputId": "c261f9ac-8770-4af1-ae5a-15a630faae51"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files updated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Comprehensive System Test\n",
        "import importlib\n",
        "from ingredient_processor import IngredientProcessor\n",
        "from recipe_generator import RecipeGenerator\n",
        "\n",
        "# Initialize components\n",
        "config = Config()\n",
        "ingredient_proc = IngredientProcessor(config)\n",
        "recipe_gen = RecipeGenerator(config)\n",
        "\n",
        "# Print data statistics\n",
        "ingredient_proc.print_data_stats()\n",
        "\n",
        "# Test ingredient substitutions\n",
        "test_ingredients = [\n",
        "    \"chicken\",\n",
        "    \"tomatoes\",\n",
        "    \"onion\",\n",
        "    \"garlic\",\n",
        "    \"bell peppers\",\n",
        "    \"carrots\"\n",
        "]\n",
        "\n",
        "print(\"\\n=== Testing Smart Substitutions ===\")\n",
        "for ingredient in test_ingredients:\n",
        "    try:\n",
        "        print(f\"\\nSubstitutes for {ingredient}:\")\n",
        "        substitutes = ingredient_proc.suggest_substitutions(ingredient)\n",
        "        for sub in substitutes:\n",
        "            print(f\"- {sub['name']} (Category: {sub['category']}, Similarity: {sub['similarity']:.3f})\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Cannot find substitutes for {ingredient}: {str(e)}\")\n",
        "\n",
        "# Test recipe generation with variations\n",
        "print(\"\\n=== Testing Recipe Generation with Variations ===\")\n",
        "base_recipe = [\"chicken\", \"rice\", \"tomatoes\", \"onion\", \"garlic\"]\n",
        "print(\"\\nOriginal ingredients:\", base_recipe)\n",
        "\n",
        "variations = ingredient_proc.generate_recipe_variations(base_recipe, n_variations=2)\n",
        "for i, variation in enumerate(variations, 1):\n",
        "    print(f\"\\nVariation {i} ingredients:\", variation)\n",
        "    recipe = recipe_gen.generate_recipe(variation)\n",
        "    print(\"Recipe:\", recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4334RX-8SzzS",
        "outputId": "2638ae99-12e6-4eb3-ee84-0da6e9fd1979"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Statistics:\n",
            "Total nodes in dataset: 8297\n",
            "Valid ingredients with embeddings: 2552\n",
            "Total categories: 17\n",
            "\n",
            "Sample of valid ingredients:\n",
            "['barbecue_seasoning' 'karo_syrup' 'tomato_juice' 'dijon_mustard' 'tea']\n",
            "\n",
            "=== Testing Smart Substitutions ===\n",
            "\n",
            "Substitutes for chicken:\n",
            "- beef (Category: Meat/Animal Product, Similarity: 0.861)\n",
            "- meat (Category: Meat/Animal Product, Similarity: 0.843)\n",
            "- pork (Category: Meat/Animal Product, Similarity: 0.838)\n",
            "\n",
            "Substitutes for tomatoes:\n",
            "Cannot find substitutes for tomatoes: No embedding found for ingredient 'tomatoes'\n",
            "\n",
            "Substitutes for onion:\n",
            "- paprika (Category: Plant/Vegetable, Similarity: 0.876)\n",
            "- basil (Category: Plant/Vegetable, Similarity: 0.865)\n",
            "- pepper (Category: Spice, Similarity: 0.896)\n",
            "\n",
            "Substitutes for garlic:\n",
            "- beef_mince (Category: Unknown, Similarity: 0.499)\n",
            "- boneless_chicken (Category: Unknown, Similarity: 0.490)\n",
            "- brinjal (Category: Unknown, Similarity: 0.474)\n",
            "\n",
            "Substitutes for bell peppers:\n",
            "Cannot find substitutes for bell peppers: No embedding found for ingredient 'bell peppers'\n",
            "\n",
            "Substitutes for carrots:\n",
            "Cannot find substitutes for carrots: No embedding found for ingredient 'carrots'\n",
            "\n",
            "=== Testing Recipe Generation with Variations ===\n",
            "\n",
            "Original ingredients: ['chicken', 'rice', 'tomatoes', 'onion', 'garlic']\n",
            "\n",
            "Variation 1 ingredients: ['chicken', 'wild_rice', 'tomatoes', 'onion', 'beef_mince']\n",
            "Recipe: title: wild rice soup recipe ingredients: 3 pound chicken 1 pound wild rice 2 cans tomatoes 1 onion, minced 1 can beef_mince 2 c. beef_spinach directions: boil chicken in large pot. remove from heat and cold. debone chicken and save broth. saute/fry onion in butter till clear. add in chicken broth, rice, tomatoes, and beefmince. cook till rice is tender.\n",
            "\n",
            "Variation 2 ingredients: ['beef', 'rice', 'tomatoes', 'onion', 'garlic']\n",
            "Recipe: title: spanish rice and meat casserole ingredients: 1 lb. beef or veal shanks 1 c. uncooked rice 1 large can tomatoes 1 onion, chopped 2 cloves garlic, crushed 1 envelope lipton beefy onion soup mix 1 1/2 cs. cook and drain meat. generate recipe 1 can tomatoes, cut up 1 medium onion, sliced garlic to taste 2 tbsp. butter or oleo directions: brown meat on both sides. place rice in bottom of casserole. put meat mixture over rice. layer tomatoes, onion, garlic, meat and rice. pour 1 cup of water over top. bake at 350 for 1 hour. serves 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPqiQM2tQjZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqE9KfEZG6a5gUv+5Y7LTX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}